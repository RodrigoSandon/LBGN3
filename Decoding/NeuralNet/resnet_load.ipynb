{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim \n",
    "from time import time\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "  expansion = 1\n",
    "\n",
    "  def __init__(self, in_planes, planes, stride=1):\n",
    "    super(BasicBlock, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(\n",
    "        in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "    self.bn1 = nn.BatchNorm2d(planes)\n",
    "    self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                            stride=1, padding=1, bias=False)\n",
    "    self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "    self.shortcut = nn.Sequential()\n",
    "    if stride != 1 or in_planes != self.expansion*planes:\n",
    "        self.shortcut = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                      kernel_size=1, stride=stride, bias=False),\n",
    "            nn.BatchNorm2d(self.expansion*planes)\n",
    "        )\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = F.relu(self.bn1(self.conv1(x)))\n",
    "    out = self.bn2(self.conv2(out))\n",
    "    out += self.shortcut(x)\n",
    "    out = F.relu(out)\n",
    "    return out\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "  expansion = 4\n",
    "\n",
    "  def __init__(self, in_planes, planes, stride=1):\n",
    "    super(Bottleneck, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "    self.bn1 = nn.BatchNorm2d(planes)\n",
    "    self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                            stride=stride, padding=1, bias=False)\n",
    "    self.bn2 = nn.BatchNorm2d(planes)\n",
    "    self.conv3 = nn.Conv2d(planes, self.expansion *\n",
    "                            planes, kernel_size=1, bias=False)\n",
    "    self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "    self.shortcut = nn.Sequential()\n",
    "    if stride != 1 or in_planes != self.expansion*planes:\n",
    "        self.shortcut = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                      kernel_size=1, stride=stride, bias=False),\n",
    "            nn.BatchNorm2d(self.expansion*planes)\n",
    "        )\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = F.relu(self.bn1(self.conv1(x)))\n",
    "    out = F.relu(self.bn2(self.conv2(out)))\n",
    "    out = self.bn3(self.conv3(out))\n",
    "    out += self.shortcut(x)\n",
    "    out = F.relu(out)\n",
    "    return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=2):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        #in channels (1), 64\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=11, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        #print(out)\n",
    "        #print(type(out))\n",
    "        #print(out.shape)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "def ResNet18():\n",
    "  return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "class FeatureDataset(Dataset):\n",
    "  \n",
    "  def __init__(self, file_name):\n",
    "    self.x_train = []\n",
    "    self.y_train = []\n",
    "    self.X_train = []\n",
    "    self.Y_train = []\n",
    "\n",
    "    count = 0\n",
    "    \n",
    "    name = {\n",
    "        'Large': 0,\n",
    "        'Small': 1,\n",
    "    }\n",
    "    \"\"\"for root,dirs,files in os.walk(file_name):\n",
    "      print(dirs)\n",
    "      y = name[dirs]\n",
    "      for name in files:\"\"\"\n",
    "    #read csv file and load row data into variables\n",
    "    for subdir in os.listdir(file_name):\n",
    "      for fname in os.listdir(os.path.join(file_name, subdir)):\n",
    "        full_path = os.path.join(file_name, subdir, fname)\n",
    "        y = name[subdir]\n",
    "        #filename = os.path.join(root,name)\n",
    "        file_out = pd.read_csv(full_path, header = None) #if don't say header is none, first row will be used as header\n",
    "        file_out = file_out.iloc[:,1:]\n",
    "        x = file_out.iloc[0:len(file_out), 0:len(file_out)].values\n",
    "        x = x[1:].astype(np.float32) # ommitting the column headers (cell names)\n",
    "        #print(x[0])\n",
    "        self.x_train.append(x)\n",
    "        #print(\"x_train:\", x_train)\n",
    "        # y = file_out.iloc[0:32, 0:32].values\n",
    "        self.y_train.append(y)\n",
    "        #Converting to tensors\n",
    "        X = torch.tensor(x, dtype=torch.float32) #converting to tensors (used to be self.X_train)\n",
    "        self.X_train.append(X)\n",
    "        #print(\"X_train size: \",X_train.shape)\n",
    "        Y = torch.tensor(y)\n",
    "        #print(\"Y_train size: \",Y_train.shape)\n",
    "        self.Y_train.append(Y)\n",
    "        count += 1\n",
    "        #print(count)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.y_train)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.X_train[idx], self.Y_train[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_count, all_count = 0, 0\n",
    "\n",
    "correct = 0.00\n",
    "total = 0.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = FeatureDataset(\"/media/rory/Padlock_DT/BLA_Analysis/Decoding/Pearson_Input_Datasets/Neural_Net_2/RDT D1/Reward Size_Choice Time (s)/train\")\n",
    "test_set = FeatureDataset(\"/media/rory/Padlock_DT/BLA_Analysis/Decoding/Pearson_Input_Datasets/Neural_Net_2/RDT D1/Reward Size_Choice Time (s)/test\")\n",
    "val_set = FeatureDataset(\"/media/rory/Padlock_DT/BLA_Analysis/Decoding/Pearson_Input_Datasets/Neural_Net_2/RDT D1/Reward Size_Choice Time (s)/val\")\n",
    "cats = [\"Large\", \"Small\"]\n",
    "test_set.X_train\n",
    "\n",
    "mini_batch_size = 1\n",
    "trainloader = torch.utils.data.DataLoader(train_set, batch_size=mini_batch_size)\n",
    "testloader = torch.utils.data.DataLoader(test_set, batch_size=mini_batch_size)\n",
    "valloader = torch.utils.data.DataLoader(val_set, batch_size=mini_batch_size)\n",
    "cats = [\"Large\", \"Small\"]\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "val_kappa = []\n",
    "test_accuracies = []\n",
    "valid_accuracies = []\n",
    "kappa_epoch = []\n",
    "time0 = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda available\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"cuda available\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Training Loss: 0.068058 | Val. Loss: 0.480660 \n",
      "Validation loss decreased (inf --> 0.480660).  Saving model ...\n",
      "Epoch: 1 | Training Loss: 0.744693 | Val. Loss: 5.265843 \n",
      "Epoch: 2 | Training Loss: 0.459028 | Val. Loss: 3.312528 \n",
      "Epoch: 3 | Training Loss: 0.340540 | Val. Loss: 2.449652 \n",
      "Epoch: 4 | Training Loss: 0.322891 | Val. Loss: 2.313371 \n",
      "Epoch: 5 | Training Loss: 0.353937 | Val. Loss: 2.530780 \n",
      "Epoch: 6 | Training Loss: 0.359246 | Val. Loss: 2.571189 \n",
      "Epoch: 7 | Training Loss: 0.352046 | Val. Loss: 2.520885 \n",
      "Epoch: 8 | Training Loss: 0.350703 | Val. Loss: 2.510727 \n",
      "Epoch: 9 | Training Loss: 0.326249 | Val. Loss: 2.337885 \n",
      "Epoch: 10 | Training Loss: 0.344779 | Val. Loss: 2.466435 \n",
      "Epoch: 11 | Training Loss: 0.345041 | Val. Loss: 2.470003 \n",
      "Epoch: 12 | Training Loss: 0.337642 | Val. Loss: 2.417798 \n",
      "Epoch: 13 | Training Loss: 0.320374 | Val. Loss: 2.295146 \n",
      "Epoch: 14 | Training Loss: 0.314278 | Val. Loss: 2.250443 \n",
      "Epoch: 15 | Training Loss: 0.302065 | Val. Loss: 2.163589 \n",
      "Epoch: 16 | Training Loss: 0.308156 | Val. Loss: 2.205441 \n",
      "Epoch: 17 | Training Loss: 0.296375 | Val. Loss: 2.122792 \n",
      "Epoch: 18 | Training Loss: 0.321146 | Val. Loss: 2.296629 \n",
      "Epoch: 19 | Training Loss: 0.314636 | Val. Loss: 2.252980 \n",
      "Epoch: 20 | Training Loss: 0.312981 | Val. Loss: 2.240718 \n",
      "Epoch: 21 | Training Loss: 0.303604 | Val. Loss: 2.174325 \n",
      "Epoch: 22 | Training Loss: 0.295246 | Val. Loss: 2.114403 \n",
      "Epoch: 23 | Training Loss: 0.289086 | Val. Loss: 2.070097 \n",
      "Epoch: 24 | Training Loss: 0.287403 | Val. Loss: 2.057612 \n",
      "Epoch: 25 | Training Loss: 0.283713 | Val. Loss: 2.031383 \n",
      "Epoch: 26 | Training Loss: 0.282869 | Val. Loss: 2.025072 \n",
      "Epoch: 27 | Training Loss: 0.285616 | Val. Loss: 2.044385 \n",
      "Epoch: 28 | Training Loss: 0.281865 | Val. Loss: 2.018155 \n",
      "Epoch: 29 | Training Loss: 0.289192 | Val. Loss: 2.069546 \n",
      "Epoch: 30 | Training Loss: 0.284685 | Val. Loss: 2.038405 \n",
      "Epoch: 31 | Training Loss: 0.281621 | Val. Loss: 2.016353 \n",
      "Epoch: 32 | Training Loss: 0.285108 | Val. Loss: 2.040678 \n",
      "Epoch: 33 | Training Loss: 0.284698 | Val. Loss: 2.038112 \n",
      "Epoch: 34 | Training Loss: 0.278658 | Val. Loss: 1.995416 \n",
      "Epoch: 35 | Training Loss: 0.311811 | Val. Loss: 2.228991 \n",
      "Epoch: 36 | Training Loss: 0.334073 | Val. Loss: 2.389349 \n",
      "Epoch: 37 | Training Loss: 0.334758 | Val. Loss: 2.396344 \n",
      "Epoch: 38 | Training Loss: 0.334425 | Val. Loss: 2.394088 \n",
      "Epoch: 39 | Training Loss: 0.345578 | Val. Loss: 2.472826 \n",
      "Epoch: 40 | Training Loss: 0.348983 | Val. Loss: 2.497931 \n",
      "Epoch: 41 | Training Loss: 0.354776 | Val. Loss: 2.539185 \n",
      "Epoch: 42 | Training Loss: 0.354706 | Val. Loss: 2.539243 \n",
      "Epoch: 43 | Training Loss: 0.347590 | Val. Loss: 2.488985 \n",
      "Epoch: 44 | Training Loss: 0.354213 | Val. Loss: 2.535090 \n",
      "Epoch: 45 | Training Loss: 0.364858 | Val. Loss: 2.610886 \n",
      "Epoch: 46 | Training Loss: 0.378912 | Val. Loss: 2.711161 \n",
      "Epoch: 47 | Training Loss: 0.418606 | Val. Loss: 2.992846 \n",
      "Epoch: 48 | Training Loss: 0.406093 | Val. Loss: 2.908255 \n",
      "Epoch: 49 | Training Loss: 0.406512 | Val. Loss: 2.910088 \n",
      "Epoch: 50 | Training Loss: 0.423254 | Val. Loss: 3.028347 \n",
      "Epoch: 51 | Training Loss: 0.428416 | Val. Loss: 3.066393 \n",
      "Epoch: 52 | Training Loss: 0.432672 | Val. Loss: 3.096962 \n",
      "Epoch: 53 | Training Loss: 0.444531 | Val. Loss: 3.181127 \n",
      "Epoch: 54 | Training Loss: 0.482806 | Val. Loss: 3.452574 \n",
      "Epoch: 55 | Training Loss: 0.499616 | Val. Loss: 3.574939 \n",
      "Epoch: 56 | Training Loss: 0.526732 | Val. Loss: 3.768095 \n",
      "Epoch: 57 | Training Loss: 0.574841 | Val. Loss: 4.110461 \n",
      "Epoch: 58 | Training Loss: 0.619633 | Val. Loss: 4.431399 \n",
      "Epoch: 59 | Training Loss: 0.635164 | Val. Loss: 4.545408 \n",
      "Epoch: 60 | Training Loss: 0.609438 | Val. Loss: 4.365253 \n",
      "Epoch: 61 | Training Loss: 0.611961 | Val. Loss: 4.380660 \n",
      "Epoch: 62 | Training Loss: 0.390947 | Val. Loss: 2.819952 \n",
      "Epoch: 63 | Training Loss: 0.564434 | Val. Loss: 4.024271 \n",
      "Epoch: 64 | Training Loss: 0.551292 | Val. Loss: 3.947563 \n",
      "Epoch: 65 | Training Loss: 0.431122 | Val. Loss: 3.097868 \n",
      "Epoch: 66 | Training Loss: 0.410229 | Val. Loss: 2.938908 \n",
      "Epoch: 67 | Training Loss: 0.361724 | Val. Loss: 2.594188 \n",
      "Epoch: 68 | Training Loss: 0.382571 | Val. Loss: 2.736787 \n",
      "Epoch: 69 | Training Loss: 0.359055 | Val. Loss: 2.572607 \n",
      "Epoch: 70 | Training Loss: 0.330101 | Val. Loss: 2.365924 \n",
      "Epoch: 71 | Training Loss: 0.306945 | Val. Loss: 2.199611 \n",
      "Epoch: 72 | Training Loss: 0.265386 | Val. Loss: 1.903865 \n",
      "Epoch: 73 | Training Loss: 0.227306 | Val. Loss: 1.630948 \n",
      "Epoch: 74 | Training Loss: 0.283222 | Val. Loss: 2.022185 \n",
      "Epoch: 75 | Training Loss: 0.322813 | Val. Loss: 2.307040 \n",
      "Epoch: 76 | Training Loss: 0.266887 | Val. Loss: 1.915893 \n",
      "Epoch: 77 | Training Loss: 0.276020 | Val. Loss: 1.975157 \n",
      "Epoch: 78 | Training Loss: 0.222947 | Val. Loss: 1.601113 \n",
      "Epoch: 79 | Training Loss: 0.235335 | Val. Loss: 1.683591 \n",
      "Epoch: 80 | Training Loss: 0.203850 | Val. Loss: 1.462317 \n",
      "Epoch: 81 | Training Loss: 0.207366 | Val. Loss: 1.484183 \n",
      "Epoch: 82 | Training Loss: 0.240824 | Val. Loss: 1.720773 \n",
      "Epoch: 83 | Training Loss: 0.230967 | Val. Loss: 1.654332 \n",
      "Epoch: 84 | Training Loss: 0.186991 | Val. Loss: 1.342861 \n",
      "Epoch: 85 | Training Loss: 0.208166 | Val. Loss: 1.488235 \n",
      "Epoch: 86 | Training Loss: 0.187923 | Val. Loss: 1.347209 \n",
      "Epoch: 87 | Training Loss: 0.159493 | Val. Loss: 1.144530 \n",
      "Epoch: 88 | Training Loss: 0.139362 | Val. Loss: 0.999632 \n",
      "Epoch: 89 | Training Loss: 0.127182 | Val. Loss: 0.911666 \n",
      "Epoch: 90 | Training Loss: 0.127111 | Val. Loss: 0.909978 \n",
      "Epoch: 91 | Training Loss: 0.124415 | Val. Loss: 0.890910 \n",
      "Epoch: 92 | Training Loss: 0.118219 | Val. Loss: 0.846900 \n",
      "Epoch: 93 | Training Loss: 0.115729 | Val. Loss: 0.828725 \n",
      "Epoch: 94 | Training Loss: 0.138252 | Val. Loss: 0.987544 \n",
      "Epoch: 95 | Training Loss: 0.098261 | Val. Loss: 0.707238 \n",
      "Epoch: 96 | Training Loss: 0.113956 | Val. Loss: 0.814328 \n",
      "Epoch: 97 | Training Loss: 0.131299 | Val. Loss: 0.938243 \n",
      "Epoch: 98 | Training Loss: 0.100012 | Val. Loss: 0.718941 \n",
      "Epoch: 99 | Training Loss: 0.106099 | Val. Loss: 0.758992 \n",
      "Epoch: 100 | Training Loss: 0.085894 | Val. Loss: 0.616825 \n",
      "Epoch: 101 | Training Loss: 0.080020 | Val. Loss: 0.573438 \n",
      "Epoch: 102 | Training Loss: 0.071094 | Val. Loss: 0.509814 \n",
      "Epoch: 103 | Training Loss: 0.090041 | Val. Loss: 0.642769 \n",
      "Epoch: 104 | Training Loss: 0.142236 | Val. Loss: 1.013179 \n",
      "Epoch: 105 | Training Loss: 0.106097 | Val. Loss: 0.762917 \n",
      "Epoch: 106 | Training Loss: 0.067818 | Val. Loss: 0.489224 \n",
      "Epoch: 107 | Training Loss: 0.043139 | Val. Loss: 0.311250 \n",
      "Validation loss decreased (0.480660 --> 0.311250).  Saving model ...\n",
      "Epoch: 108 | Training Loss: 0.051782 | Val. Loss: 0.369898 \n",
      "Epoch: 109 | Training Loss: 0.036507 | Val. Loss: 0.262801 \n",
      "Validation loss decreased (0.311250 --> 0.262801).  Saving model ...\n",
      "Epoch: 110 | Training Loss: 0.051748 | Val. Loss: 0.369005 \n",
      "Epoch: 111 | Training Loss: 0.047177 | Val. Loss: 0.338142 \n",
      "Epoch: 112 | Training Loss: 0.049572 | Val. Loss: 0.354649 \n",
      "Epoch: 113 | Training Loss: 0.059816 | Val. Loss: 0.427220 \n",
      "Epoch: 114 | Training Loss: 0.065521 | Val. Loss: 0.468486 \n",
      "Epoch: 115 | Training Loss: 0.032306 | Val. Loss: 0.234460 \n",
      "Validation loss decreased (0.262801 --> 0.234460).  Saving model ...\n",
      "Epoch: 116 | Training Loss: 0.040542 | Val. Loss: 0.289483 \n",
      "Epoch: 117 | Training Loss: 0.050557 | Val. Loss: 0.360949 \n",
      "Epoch: 118 | Training Loss: 0.056731 | Val. Loss: 0.405515 \n",
      "Epoch: 119 | Training Loss: 0.067557 | Val. Loss: 0.482573 \n",
      "Epoch: 120 | Training Loss: 0.040389 | Val. Loss: 0.291731 \n",
      "Epoch: 121 | Training Loss: 0.024947 | Val. Loss: 0.180117 \n",
      "Validation loss decreased (0.234460 --> 0.180117).  Saving model ...\n",
      "Epoch: 122 | Training Loss: 0.022782 | Val. Loss: 0.163321 \n",
      "Validation loss decreased (0.180117 --> 0.163321).  Saving model ...\n",
      "Epoch: 123 | Training Loss: 0.028557 | Val. Loss: 0.203882 \n",
      "Epoch: 124 | Training Loss: 0.028135 | Val. Loss: 0.201442 \n",
      "Epoch: 125 | Training Loss: 0.005235 | Val. Loss: 0.039679 \n",
      "Validation loss decreased (0.163321 --> 0.039679).  Saving model ...\n",
      "Epoch: 126 | Training Loss: 0.000844 | Val. Loss: 0.006499 \n",
      "Validation loss decreased (0.039679 --> 0.006499).  Saving model ...\n",
      "Epoch: 127 | Training Loss: 0.000554 | Val. Loss: 0.003999 \n",
      "Validation loss decreased (0.006499 --> 0.003999).  Saving model ...\n",
      "Epoch: 128 | Training Loss: 0.000458 | Val. Loss: 0.003291 \n",
      "Validation loss decreased (0.003999 --> 0.003291).  Saving model ...\n",
      "Epoch: 129 | Training Loss: 0.000395 | Val. Loss: 0.002831 \n",
      "Validation loss decreased (0.003291 --> 0.002831).  Saving model ...\n",
      "Epoch: 130 | Training Loss: 0.000348 | Val. Loss: 0.002494 \n",
      "Validation loss decreased (0.002831 --> 0.002494).  Saving model ...\n",
      "Epoch: 131 | Training Loss: 0.000312 | Val. Loss: 0.002235 \n",
      "Validation loss decreased (0.002494 --> 0.002235).  Saving model ...\n",
      "Epoch: 132 | Training Loss: 0.000283 | Val. Loss: 0.002029 \n",
      "Validation loss decreased (0.002235 --> 0.002029).  Saving model ...\n",
      "Epoch: 133 | Training Loss: 0.000260 | Val. Loss: 0.001860 \n",
      "Validation loss decreased (0.002029 --> 0.001860).  Saving model ...\n",
      "Epoch: 134 | Training Loss: 0.000240 | Val. Loss: 0.001720 \n",
      "Validation loss decreased (0.001860 --> 0.001720).  Saving model ...\n",
      "Epoch: 135 | Training Loss: 0.000223 | Val. Loss: 0.001600 \n",
      "Validation loss decreased (0.001720 --> 0.001600).  Saving model ...\n",
      "Epoch: 136 | Training Loss: 0.000209 | Val. Loss: 0.001497 \n",
      "Validation loss decreased (0.001600 --> 0.001497).  Saving model ...\n",
      "Epoch: 137 | Training Loss: 0.000196 | Val. Loss: 0.001407 \n",
      "Validation loss decreased (0.001497 --> 0.001407).  Saving model ...\n",
      "Epoch: 138 | Training Loss: 0.000185 | Val. Loss: 0.001328 \n",
      "Validation loss decreased (0.001407 --> 0.001328).  Saving model ...\n",
      "Epoch: 139 | Training Loss: 0.000175 | Val. Loss: 0.001257 \n",
      "Validation loss decreased (0.001328 --> 0.001257).  Saving model ...\n",
      "Epoch: 140 | Training Loss: 0.000167 | Val. Loss: 0.001194 \n",
      "Validation loss decreased (0.001257 --> 0.001194).  Saving model ...\n",
      "Epoch: 141 | Training Loss: 0.000159 | Val. Loss: 0.001137 \n",
      "Validation loss decreased (0.001194 --> 0.001137).  Saving model ...\n",
      "Epoch: 142 | Training Loss: 0.000152 | Val. Loss: 0.001086 \n",
      "Validation loss decreased (0.001137 --> 0.001086).  Saving model ...\n",
      "Epoch: 143 | Training Loss: 0.000145 | Val. Loss: 0.001039 \n",
      "Validation loss decreased (0.001086 --> 0.001039).  Saving model ...\n",
      "Epoch: 144 | Training Loss: 0.000139 | Val. Loss: 0.000996 \n",
      "Validation loss decreased (0.001039 --> 0.000996).  Saving model ...\n",
      "Epoch: 145 | Training Loss: 0.000134 | Val. Loss: 0.000957 \n",
      "Validation loss decreased (0.000996 --> 0.000957).  Saving model ...\n",
      "Epoch: 146 | Training Loss: 0.000129 | Val. Loss: 0.000921 \n",
      "Validation loss decreased (0.000957 --> 0.000921).  Saving model ...\n",
      "Epoch: 147 | Training Loss: 0.000124 | Val. Loss: 0.000887 \n",
      "Validation loss decreased (0.000921 --> 0.000887).  Saving model ...\n",
      "Epoch: 148 | Training Loss: 0.000120 | Val. Loss: 0.000856 \n",
      "Validation loss decreased (0.000887 --> 0.000856).  Saving model ...\n",
      "Epoch: 149 | Training Loss: 0.000115 | Val. Loss: 0.000827 \n",
      "Validation loss decreased (0.000856 --> 0.000827).  Saving model ...\n",
      "Epoch: 150 | Training Loss: 0.000112 | Val. Loss: 0.000800 \n",
      "Validation loss decreased (0.000827 --> 0.000800).  Saving model ...\n",
      "Epoch: 151 | Training Loss: 0.000108 | Val. Loss: 0.000775 \n",
      "Validation loss decreased (0.000800 --> 0.000775).  Saving model ...\n",
      "Epoch: 152 | Training Loss: 0.000105 | Val. Loss: 0.000751 \n",
      "Validation loss decreased (0.000775 --> 0.000751).  Saving model ...\n",
      "Epoch: 153 | Training Loss: 0.000102 | Val. Loss: 0.000729 \n",
      "Validation loss decreased (0.000751 --> 0.000729).  Saving model ...\n",
      "Epoch: 154 | Training Loss: 0.000099 | Val. Loss: 0.000708 \n",
      "Validation loss decreased (0.000729 --> 0.000708).  Saving model ...\n",
      "Epoch: 155 | Training Loss: 0.000096 | Val. Loss: 0.000688 \n",
      "Validation loss decreased (0.000708 --> 0.000688).  Saving model ...\n",
      "Epoch: 156 | Training Loss: 0.000093 | Val. Loss: 0.000669 \n",
      "Validation loss decreased (0.000688 --> 0.000669).  Saving model ...\n",
      "Epoch: 157 | Training Loss: 0.000091 | Val. Loss: 0.000652 \n",
      "Validation loss decreased (0.000669 --> 0.000652).  Saving model ...\n",
      "Epoch: 158 | Training Loss: 0.000089 | Val. Loss: 0.000635 \n",
      "Validation loss decreased (0.000652 --> 0.000635).  Saving model ...\n",
      "Epoch: 159 | Training Loss: 0.000086 | Val. Loss: 0.000619 \n",
      "Validation loss decreased (0.000635 --> 0.000619).  Saving model ...\n",
      "Epoch: 160 | Training Loss: 0.000084 | Val. Loss: 0.000604 \n",
      "Validation loss decreased (0.000619 --> 0.000604).  Saving model ...\n",
      "Epoch: 161 | Training Loss: 0.000082 | Val. Loss: 0.000589 \n",
      "Validation loss decreased (0.000604 --> 0.000589).  Saving model ...\n",
      "Epoch: 162 | Training Loss: 0.000080 | Val. Loss: 0.000576 \n",
      "Validation loss decreased (0.000589 --> 0.000576).  Saving model ...\n",
      "Epoch: 163 | Training Loss: 0.000079 | Val. Loss: 0.000563 \n",
      "Validation loss decreased (0.000576 --> 0.000563).  Saving model ...\n",
      "Epoch: 164 | Training Loss: 0.000077 | Val. Loss: 0.000550 \n",
      "Validation loss decreased (0.000563 --> 0.000550).  Saving model ...\n",
      "Epoch: 165 | Training Loss: 0.000075 | Val. Loss: 0.000538 \n",
      "Validation loss decreased (0.000550 --> 0.000538).  Saving model ...\n",
      "Epoch: 166 | Training Loss: 0.000074 | Val. Loss: 0.000527 \n",
      "Validation loss decreased (0.000538 --> 0.000527).  Saving model ...\n",
      "Epoch: 167 | Training Loss: 0.000072 | Val. Loss: 0.000516 \n",
      "Validation loss decreased (0.000527 --> 0.000516).  Saving model ...\n",
      "Epoch: 168 | Training Loss: 0.000071 | Val. Loss: 0.000505 \n",
      "Validation loss decreased (0.000516 --> 0.000505).  Saving model ...\n",
      "Epoch: 169 | Training Loss: 0.000069 | Val. Loss: 0.000495 \n",
      "Validation loss decreased (0.000505 --> 0.000495).  Saving model ...\n",
      "Epoch: 170 | Training Loss: 0.000068 | Val. Loss: 0.000485 \n",
      "Validation loss decreased (0.000495 --> 0.000485).  Saving model ...\n",
      "Epoch: 171 | Training Loss: 0.000066 | Val. Loss: 0.000476 \n",
      "Validation loss decreased (0.000485 --> 0.000476).  Saving model ...\n",
      "Epoch: 172 | Training Loss: 0.000065 | Val. Loss: 0.000467 \n",
      "Validation loss decreased (0.000476 --> 0.000467).  Saving model ...\n",
      "Epoch: 173 | Training Loss: 0.000064 | Val. Loss: 0.000459 \n",
      "Validation loss decreased (0.000467 --> 0.000459).  Saving model ...\n",
      "Epoch: 174 | Training Loss: 0.000063 | Val. Loss: 0.000450 \n",
      "Validation loss decreased (0.000459 --> 0.000450).  Saving model ...\n",
      "Epoch: 175 | Training Loss: 0.000062 | Val. Loss: 0.000442 \n",
      "Validation loss decreased (0.000450 --> 0.000442).  Saving model ...\n",
      "Epoch: 176 | Training Loss: 0.000061 | Val. Loss: 0.000434 \n",
      "Validation loss decreased (0.000442 --> 0.000434).  Saving model ...\n",
      "Epoch: 177 | Training Loss: 0.000060 | Val. Loss: 0.000427 \n",
      "Validation loss decreased (0.000434 --> 0.000427).  Saving model ...\n",
      "Epoch: 178 | Training Loss: 0.000059 | Val. Loss: 0.000420 \n",
      "Validation loss decreased (0.000427 --> 0.000420).  Saving model ...\n",
      "Epoch: 179 | Training Loss: 0.000058 | Val. Loss: 0.000413 \n",
      "Validation loss decreased (0.000420 --> 0.000413).  Saving model ...\n",
      "Epoch: 180 | Training Loss: 0.000057 | Val. Loss: 0.000406 \n",
      "Validation loss decreased (0.000413 --> 0.000406).  Saving model ...\n",
      "Epoch: 181 | Training Loss: 0.000056 | Val. Loss: 0.000400 \n",
      "Validation loss decreased (0.000406 --> 0.000400).  Saving model ...\n",
      "Epoch: 182 | Training Loss: 0.000055 | Val. Loss: 0.000393 \n",
      "Validation loss decreased (0.000400 --> 0.000393).  Saving model ...\n",
      "Epoch: 183 | Training Loss: 0.000054 | Val. Loss: 0.000387 \n",
      "Validation loss decreased (0.000393 --> 0.000387).  Saving model ...\n",
      "Epoch: 184 | Training Loss: 0.000053 | Val. Loss: 0.000381 \n",
      "Validation loss decreased (0.000387 --> 0.000381).  Saving model ...\n",
      "Epoch: 185 | Training Loss: 0.000052 | Val. Loss: 0.000375 \n",
      "Validation loss decreased (0.000381 --> 0.000375).  Saving model ...\n",
      "Epoch: 186 | Training Loss: 0.000052 | Val. Loss: 0.000370 \n",
      "Validation loss decreased (0.000375 --> 0.000370).  Saving model ...\n",
      "Epoch: 187 | Training Loss: 0.000051 | Val. Loss: 0.000364 \n",
      "Validation loss decreased (0.000370 --> 0.000364).  Saving model ...\n",
      "Epoch: 188 | Training Loss: 0.000050 | Val. Loss: 0.000359 \n",
      "Validation loss decreased (0.000364 --> 0.000359).  Saving model ...\n",
      "Epoch: 189 | Training Loss: 0.000049 | Val. Loss: 0.000354 \n",
      "Validation loss decreased (0.000359 --> 0.000354).  Saving model ...\n",
      "Epoch: 190 | Training Loss: 0.000049 | Val. Loss: 0.000349 \n",
      "Validation loss decreased (0.000354 --> 0.000349).  Saving model ...\n",
      "Epoch: 191 | Training Loss: 0.000048 | Val. Loss: 0.000344 \n",
      "Validation loss decreased (0.000349 --> 0.000344).  Saving model ...\n",
      "Epoch: 192 | Training Loss: 0.000047 | Val. Loss: 0.000340 \n",
      "Validation loss decreased (0.000344 --> 0.000340).  Saving model ...\n",
      "Epoch: 193 | Training Loss: 0.000047 | Val. Loss: 0.000335 \n",
      "Validation loss decreased (0.000340 --> 0.000335).  Saving model ...\n",
      "Epoch: 194 | Training Loss: 0.000046 | Val. Loss: 0.000331 \n",
      "Validation loss decreased (0.000335 --> 0.000331).  Saving model ...\n",
      "Epoch: 195 | Training Loss: 0.000046 | Val. Loss: 0.000326 \n",
      "Validation loss decreased (0.000331 --> 0.000326).  Saving model ...\n",
      "Epoch: 196 | Training Loss: 0.000045 | Val. Loss: 0.000322 \n",
      "Validation loss decreased (0.000326 --> 0.000322).  Saving model ...\n",
      "Epoch: 197 | Training Loss: 0.000044 | Val. Loss: 0.000318 \n",
      "Validation loss decreased (0.000322 --> 0.000318).  Saving model ...\n",
      "Epoch: 198 | Training Loss: 0.000044 | Val. Loss: 0.000314 \n",
      "Validation loss decreased (0.000318 --> 0.000314).  Saving model ...\n",
      "Epoch: 199 | Training Loss: 0.000043 | Val. Loss: 0.000310 \n",
      "Validation loss decreased (0.000314 --> 0.000310).  Saving model ...\n",
      "\n",
      "Training Time (in minutes) = 49.291114862759905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f3e5926fbb0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = ResNet18()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "model.to(device)\n",
    "\n",
    "def train(epochs, model):\n",
    "    valid_loss_min = np.Inf\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    for e in range(epochs):\n",
    "        running_loss = 0\n",
    "        for images, labels in trainloader:\n",
    "            #print(images)\n",
    "            #print(labels)\n",
    "            images = images.unsqueeze(1)\n",
    "            #print(images.shape)\n",
    "            #long(images) convert types\n",
    "            images = images.to(device)\n",
    "            #print(images.shape)\n",
    "            labels = labels.to(device)\n",
    "    \n",
    "            # Training pass\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            output = model(images).to(device)\n",
    "        \n",
    "            loss = criterion(output, labels)\n",
    "    \n",
    "            # backpropagation: calculate the gradient of the loss function w.r.t model parameters\n",
    "            loss.backward()\n",
    "    \n",
    "            # And optimizes its weights here\n",
    "            optimizer.step()\n",
    "    \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            train_loss += loss.item()*images.size(0)\n",
    "            valid_loss += loss.item()*images.size(0)\n",
    "            \n",
    "            y_actual = labels.data.cpu().numpy()\n",
    "            y_pred = output[:,-1].detach().cpu().numpy()\n",
    "            #val_kappa.append(cohen_kappa_score(y_actual, y_pred.round()))  \n",
    "        else:\n",
    "            \n",
    "            train_loss = train_loss/len(trainloader.sampler)\n",
    "            valid_loss = valid_loss/len(valloader.sampler)\n",
    "            #valid_kappa = np.mean(val_kappa)\n",
    "            #kappa_epoch.append(np.mean(val_kappa))\n",
    "            train_losses.append(train_loss)\n",
    "            valid_losses.append(valid_loss)\n",
    "            \n",
    "            print('Epoch: {} | Training Loss: {:.6f} | Val. Loss: {:.6f} '.format(\n",
    "                e, train_loss, valid_loss))\n",
    "            \n",
    "            if valid_loss <= valid_loss_min:\n",
    "                print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "                valid_loss_min,\n",
    "                valid_loss))\n",
    "                torch.save(model.state_dict(), 'trained_model_1.pt')\n",
    "                valid_loss_min = valid_loss\n",
    "    print(\"\\nTraining Time (in minutes) =\", (time()-time0)/60)\n",
    "\n",
    "\n",
    "train(200, model)\n",
    "\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(valid_losses, label='Validation loss')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network test images: 65 %\n"
     ]
    }
   ],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                         normalize=False,\n",
    "                         title='Confusion matrix',\n",
    "                         cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest',cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:,np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print(\"Confusion matrix, without normalization\")\n",
    "    print(cm)\n",
    "    \n",
    "    thresh = cm.max() / 2.\n",
    "    for i,j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j,i,cm[i,j],\n",
    "                horizontalalignment=\"center\",\n",
    "                color=\"white\" if cm[i,j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "\n",
    "actual = []\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        #print(labels.item())\n",
    "        actual.append(labels.item())\n",
    "        images = images.to(device)\n",
    "        images = images.unsqueeze(1)\n",
    "        #standard for image is 4 dimensional\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        #print(predicted)\n",
    "        predictions.append(predicted.item())\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "torch.save(model.state_dict(), \"model1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130\n",
      "130\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(actual))\n",
    "print(len(predictions))\n",
    "cm = confusion_matrix(y_true=actual, y_pred=predictions)\n",
    "#valloader.class_indices\n",
    "\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=cats,)\n",
    "#plot_confusion_matrix(cm, classes=cats, title='Confusion Matrix')\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "423c562efecaae8997fde0d41374f24698989108c3b6b226854ad1e5219d8fa7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('pyTorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
